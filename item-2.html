<!doctype html>
<html lang="en" class="no-js">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<link rel="stylesheet" href="css/reset.css"> <!-- CSS reset -->
	<link rel="stylesheet" href="css/style.css"> <!-- Resource style -->
	<script src="js/modernizr.js"></script> <!-- Modernizr -->
  	
	<title>Blended Learning at Northwestern</title>
    <meta name="authors" content="Derek Thurber and Alyssa Dyar">
    <meta name="description" content="This study is an evaluation based educational case study on the blended format courses in the Higher Education Administration and Policy graduate degree program at Northwestern University with a pragmatic research approach.">
</head>
<body>
	<div class="cd-fold-content single-page">
		<h2>Activities and Tools Used</h2>
        
		<em>In alignment with previous research on edtech adoption, emphasis should not be placed on the technology tools but rather on how those tools are used, with particular emphasis in the blended format on integration between asynchronous and synchronous activities.</em>
        
        <h3>In Brief</h3>
        
        <p>
            <strong>Coursework incorporates a variety of activities that promote communication and collaboration,</strong> including group work, discussion-based assignments, and peer reviews.
        </p>
        <p>
            <strong>The program emphasizes active learning strategies:</strong> synchronous and face-to-face sessions are leveraged to facilitate as much interaction as possible. Any activities that do not require significant interaction (lectures, video content, written assignments, quizzes, etc.) are delivered asynchronously.  
        </p>
        <p>
            <strong>An assortment of educational technology tools are employed to facilitate student engagement and discussion,</strong> including Flipgrid, Yellowdig, and Adobe Connect breakout rooms. 
        </p>
        
		<h3>Detail</h3>
        <blockquote>
            In the online sessions, activities that provided opportunities for peer interaction (small group discussions and chat-based discussions) were the most effective. I appreciated the chat-based discussions because the class was so large and they gave more students a chance to participate.”
        </blockquote>
        <p>
			In order to facilitate content delivery, student engagement, and assessment, our blended courses incorporated many different teaching and learning strategies and tools. Instructional designers worked with faculty to develop these activities based on the learning objectives, nature of the content, and modality (in-person, online synchronous, asynchronous), with a continued emphasis on promoting social presence within the course, including peer-to-peer and student-to-instructor engagement. We emphasized active learning strategies and tried to take advantage of all synchronous sessions (online and face-to-face) to facilitate as much interaction as possible, while any activities that did not require significant interaction (such as lectures, written assignments, and quizzes) were delivered asynchronously.
		</p>
            <div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;margin:15px 0;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><span class="wistia_embed wistia_async_8ivj68h818 popover=true popoverAnimateThumbnail=true videoFoam=true" style="display:inline-block;height:100%;width:100%">&nbsp;</span></div></div>
        <p>
            In ranking student-reported “helpfulness” of all tools and activities implemented within our blended courses (Figure 1), top-rated activities include a blend of content-delivery methods (guest speakers, online videos, and readings) and peer engagement activities (collaborative assignments and small group discussion). Presumably it is the blend of these activities that contributes to students’ overall understanding, and again, is heavily influenced by how the activity is integrated into the course. 
        </p>
        <a class="lightbox" href="img/activities-tools-helpfulness.png" data-featherlight="image">
            <figure>
                <img src="img/activities-tools-helpfulness.png"> 
                <figcaption>Figure 1. Helpfullness rating of all activities and tools used in blended format courses ranked in desending order. Note that not all activities/tools were used in every course.</figcaption>
            </figure>
        </a>
		<p>
			Comparing the tools used to students’ overall satisfaction in each course, we did not identify any particularly relevant trends - there was no increase in satisfaction based on the number of tools used and there was no particular tool that seemed to lead to higher satisfaction scores. This led us to consider which factors do play a role in increasing student satisfaction within a course. Initial findings from student evaluations seemed to demonstrate a relationship between overall satisfaction and quality/quantity of interaction between peers and the instructor(s),  linking more closely to quality than quantity (See Figure 2).
		</p>
        <a class="lightbox" href="img/overall-satisfaction.png" data-featherlight="image">
            <figure>
                <img src="img/overall-satisfaction.png"> 
                <figcaption>Figure 2. Overall satisfaction, amount of interaction, and quality of interaction for each course examined.</figcaption>
            </figure>
        </a>
		<p>
			If the tools and activities themselves did not lead to higher scores on these items, perhaps there are strategies the instructor(s) used which contributed. In looking at the course with the highest scores on satisfaction and amount/quality of interactions (Course 3), we found the curriculum included many of the same activities and tools as other courses, but students in this course ranked the activities as more useful. For example, Yellowdig, a social discussion tool, was used in both Course 2 and Course 3, but students in Course 3 rated the tool as more useful (see Figure 3). In both courses, students shared articles and commented on their peers’ posts. In neither course did students have specific requirements as to the number of posts or comments contributed. The only significant difference was that in Course 3, the instructor referenced the Yellowdig board during each synchronous class session, often having students share their favorite takeaways from the Yellowdig discussion. Conceivably, this connection across modalities or instructor engagement with the discussion led to higher reported usefulness of the tool. Additionally, it is perhaps these in-class discussions expanding on asynchronous work that contributed to higher scores on “quality of interactions with instructor” for Course 2.
		</p>
        <a class="lightbox" href="img/yellowdig.png" data-featherlight="image">
            <figure>
                <img src="img/yellowdig.png"> 
                <figcaption>Figure 3. Ratings of helpfulness for Yellowdig tool in Courses 2 and 3.</figcaption>
            </figure>
        </a>
        <p>&nbsp;</p>
	</div>
<script src="js/jquery-2.1.1.js"></script>
<script src="js/main.js"></script> <!-- Resource jQuery -->
</body>
</html>